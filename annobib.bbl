\newcommand{\etalchar}[1]{$^{#1}$}
\begin{thebibliography}{BWEC13}

\bibitem[AOG{\etalchar{+}}12]{6256363}
C.~Aydin, O.~Oktay, A.U. Gunebakan, R.K. Ciftci, and A.~Ademoglu.
\newblock Functional parcellation of memory related brain networks by spectral
  clustering of \ac{eeg} data.
\newblock In {\em Telecommunications and Signal Processing (TSP), 2012 35th
  International Conference on}, pages 581--585, 2012.
 \begin{quotation}\noindent Aydin et al. investigated the relationship between
  alpha-band \ac{eeg} activity and memory function. Clustering, both group and
  individual wise, was used to classify electrodes for the visuospatial tasks.
  \end{quotation}
\bibitem[BC96]{494647}
G.A. Babich and O.I. Camps.
\newblock Weighted parzen windows for pattern classification.
\newblock {\em Pattern Analysis and Machine Intelligence, IEEE Transactions
  on}, 18(5):567--570, 1996.
 \begin{quotation}\noindent Parzen windows are nonparametric classifiers that
  estimate a density function for data provided, as many data sets do not
  follow common distributions. Babich and Camps approach this by clustering
  training data to find the centers (reference vectors) and weights (window
  weights) to be used in a kernel estimator. This method makes use of a Parzen
  Window classifier estimation during training so long as these estimates do
  not exceed a certain distance from each other. Overall, this weighted
  Parzen-window classifier is less computational, requires less room, and has
  little error difference from the full classifier. \end{quotation}

\bibitem[BLUv13]{2013arXiv1302.2717B}
X.~{Bresson}, T.~{Laurent}, D.~{Uminsky}, and J.~H. {von Brecht}.
\newblock {An Adaptive Total Variation Algorithm for Computing the Balanced Cut
  of a Graph}.
\newblock {\em ArXiv e-prints}, February 2013.
 \begin{quotation}\noindent This article proposes a new method of Total
  Variation (TV) Clustering. Bresson et al. offer a novel method of choosing an
  adaptive tolerance such that the convergence of the relaxed Balance Cut
  Problem (BCP) to a solution vector is monotonic. Monotonicity of convergence
  is desirable because it leads to a more efficient, more direct convergence.
  The relaxed BCP is a minimization problem whose objective function uses a TV
  norm to measure each iteration of the minimization. A threshold must first be
  defined, and then all points can then be clustered into the two classes by
  reading indices from the solution vector. \end{quotation}

\bibitem[BWEC13]{Bridwell2013101}
David~A. Bridwell, Lei Wu, Tom Eichele, and Vince~D. Calhoun.
\newblock The spatiospectral characterization of brain networks: Fusing
  concurrent \{\ac{eeg}\} spectra and \ac{fmri} maps.
\newblock {\em NeuroImage}, 69(0):101 -- 111, 2013.
 \begin{quotation}\noindent Birdwell et al. applied group \ac{ica} separately
  to \ac{eeg} spectral signals and \ac{fmri} \ac{bold} signals, acquired
  simultaneously. Selected components of the \ac{ica} were deconvolved together
  to estimate an \ac{irf} for component pairs of each \ac{fmri} and \ac{eeg}
  components. This method treats the \ac{fmri} component time-course as the
  result of the convolution of the \ac{eeg} component time-course and the
  \ac{irf}. The deviations in the \ac{irf} are indicative of \ac{eeg} responses
  being associated with subsequent \ac{fmri} \ac{bold} signal. These results
  were analyzed for similarities in associations in each of the different
  frequencies, observing positive associations between \ac{eeg} and \ac{fmri}
  in lower and upper frequencies and negative associations in various alpha
  sources. \end{quotation}

\bibitem[CV95]{Cortes95support-vectornetworks}
Corinna Cortes and Vladimir Vapnik.
\newblock Support-vector networks.
\newblock In {\em Machine Learning}, pages 273--297, 1995.
 \begin{quotation}\noindent Support vector networks are a method of classifying
  data based on clustering of training data--requires a grand truth as well as
  binary outcomes. The support-vector machine relies on the support vectors
  given by the training data to determine an optimal hyperplane to separate the
  clusters. Larger margins usually lead to fewer errors in classification. If
  the data set is not separable, the kernel trick can be used to convert the
  problem into a comparable, although higher-dimensional, separable problem.
  \end{quotation}
\bibitem[EHM12]{Engell20122600}
Andrew~D. Engell, Scott Huettel, and Gregory McCarthy.
\newblock The \ac{fmri} \{\ac{bold}\} signal tracks electrophysiological
  spectral perturbations, not event-related potentials.
\newblock {\em NeuroImage}, 59(3):2600 -- 2606, 2012.
 \begin{quotation}\noindent Varying the duration of an external stimulus
  application results in a modulation of $\gamma$-\ac{ersp} power that is
  similar to modulation of the \ac{bold} response in certain regions of the
  brain (peri-calcarine cortex, fusiform gyrus, and lateral-temporal-occipital
  cortex). Lower-frequency \ac{ersp} power is not modulated to the same extent
  as are the $\gamma$-\ac{ersp} power and the \ac{bold} signal. This
  observation suggests that the change in \ac{bold} signal could be indicative
  of a corresponding change in $\gamma$-\ac{ersp} power. The methods used
  (wavelet decomposition with a sliding window over time) are relatively novel
  and may have yielded better temporal resolution than previous work. This
  improvement in resolution may have allowed for detection of more minute,
  temporary changes than was possible in earlier studies. Further, the
  inclusion of frequencies larger than 45 Hz into the $\gamma$-band allows for
  increased sensitivity to high-frequency signals. \end{quotation}

\bibitem[FGK{\etalchar{+}}12]{Farid01082012}
Nikdokht Farid, Holly~M. Girard, Nobuko Kemmotsu, Michael~E. Smith,
  Sebastian~W. Magda, Wei~Y. Lim, Roland~R. Lee, and Carrie~R. McDonald.
\newblock Temporal lobe epilepsy: Quantitative mr volumetry in detection of
  hippocampal atrophy.
\newblock {\em Radiology}, 264(2):542--550, 2012.
 \begin{quotation}\noindent The detection of hippocampal atrophies in epilepsy
  patients is crucial in lateralization of \ac{tle}. However, slight atrophies
  present early in the disease may be difficult to identify, even by expert
  radiologists. Farid et al., implement fully automated volumetric \ac{mri} in
  an attempt to correctly lateralize \ac{tle} in their patients. Volumetric
  analysis can confirm hippocampal cell loss, and thus is a strong indicator of
  the presence and degree of hippocampal atrophy. Individual patient's brain
  scans were normalized with respect to age and sex, and then compared to
  appropriate norms in order to determine if atrophy was present. Although this
  volumetric approach was successful in determining the presence and laterality
  of these atrophies, it is best used as an aid to visual analysis.
  \end{quotation}

\bibitem[FYS{\etalchar{+}}12]{Focke2012356}
Niels~K. Focke, Mahinda Yogarajah, Mark~R. Symms, Oliver Gruber, Walter Paulus,
  and John~S. Duncan.
\newblock Automated \{MR\} image classification in temporal lobe epilepsy.
\newblock {\em NeuroImage}, 59(1):356 -- 362, 2012.
\newblock Neuroergonomics: The human brain in action and at work.
 \begin{quotation}\noindent Support vector machines can be used to classify
  between left \ac{mtle}, right \ac{mtle}, and the control group (no unilateral
  \ac{mtle}), with or without marked \ac{hs}. The classification/diagnosis was
  particularly accurate when gray matter based segmentation and \ac{dti} were
  implemented. When dealing with \ac{mtle}, it can be beneficial to use local
  weighting. \end{quotation}

\bibitem[HO00]{Hyvärinen00independentcomponent}
Aapo Hyvärinen and Erkki Oja.
\newblock Independent component analysis: algorithms and applications.
\newblock {\em Neural Networks}, 13:411--430, 2000.
 \begin{quotation}\noindent Hyvärinen and Oja give an overview of Independent
  Component Analysis (\ac{ica}) and its implementation in recovering individual
  data samples from multivariate data. This separation of data is achieved
  through application dependent preprocessing of the data, such as centering
  and whitening and utilizing an algorithm that maximizes the contrast function
  of components. The application of \ac{ica} becomes useful in the separation
  of individual brain activity components from measured potentials in \ac{eeg},
  the separation of brain activity from artifacts in the data (eye movements or
  blinks, or malfunctions in sensors), and also in the denoising of images.
  \end{quotation}

\bibitem[HR11]{Henry2011194}
Thomas~R. Henry and Deborah~D. Roman.
\newblock Presurgical epilepsy localization with interictal cerebral
  dysfunction.
\newblock {\em Epilepsy \& Behavior}, 20(2):194 -- 208, 2011.
 \begin{quotation}\noindent Accurate localization is crucial to the success of
  resection aimed towards curing \ac{tle}. \ac{fdgpet} is valuable in planning
  resection surgery and predicting surgical outcomes. Different types of
  epilepsy can characterized by the apparent hypometabolism observed in regions
  such as the mesial and lateral temporal lobe. \end{quotation}

\bibitem[KCA{\etalchar{+}}13]{kerr-balancing}
W.T. Kerr, A.Y. Cho, A.~Anderson, P.K. Douglas, S.T. Nguyen, N.M. Reddy, E.P.
  Lau, E.S. Hwang, K.R. Raman, A.~Trefler, D.H. Silverman, and M.S. Cohen.
\newblock Balancing clinical and pathological relevance in machine learning
  diagnosis of epilepsy.
\newblock In {\em 3rd International Workshop Pattern Recognition in Neuron
  Aging}, Philadelphia, PA, USA, 2013.
 \begin{quotation}\noindent [Filler citation for now--likely contains errors.]
  It is important to consider when evaluating machine learning used in the
  diagnosis of epilepsy the control group--whether the comparison group is
  normal or \ac{pwn}. Kerr et al. argue that because the clinical question in
  epilepsy diagnosis is whether patients are \ac{pwe} or \ac{pwn} given that
  seizures are already present, the control group should be \ac{pwn}. That is,
  the clinical comparison is between patients with epileptic seizures and those
  with non-epileptic seizures, not between patients with epileptic seizures and
  those whom not present seizures. \end{quotation}
\bibitem[KNC{\etalchar{+}}13]{kerr-computer}
Wesley~T. Kerr, Stefan~T. Nguyen, Andrew~Y. Cho, Edward~P Lau, Daniel~H.
  Silverman, Pamela~K. Douglas, Navya~M. Reddy, Ariana Anderson, Jennifer
  Bramen, and Noriko Salamon.
\newblock Computer-aided diagnosis and localization of lateralized temporal
  lobe epilepsy using interictal {FDG-PET}.
\newblock {\em Frontiers in Neurology}, 2013.
 \begin{quotation}\noindent Kerr et al. focus on the problem of diagnosing
  \ac{pwe} verus \ac{pwn} using a \ac{cad} tool. The model used involved
  partitioning \ac{fdgpet} data into 47 \ac{roi} and incorporating the
  metabolic activity of each \ac{roi} in training a \ac{mlp} evaluated with
  \ac{cl10cv}. \end{quotation}

\bibitem[LS00]{Lee00algorithmsfor}
Daniel~D. Lee and H.~Sebastian Seung.
\newblock Algorithms for non-negative matrix factorization.
\newblock In {\em In NIPS}, pages 556--562. MIT Press, 2000.
 \begin{quotation}\noindent Many data classification techniques rely on matrix
  factorizations. When the data set at hand is guaranteed to be nonnegative
  (i.e. the physical measurements only take on nonnegative values) the
  nonnegative matrix factorization (NMF) method may be useful. NMF is an
  alternative strategy to using SVD or PCA. This paper examines different
  techniques which can be used to compute the NMF which will approximate a
  general nonnegative matrix. \end{quotation}
\bibitem[ML10]{mulert2010eeg}
C.~Mulert and L.~Lemieux.
\newblock {\em Eeg - Fmri: Physiological Basis, Technique, and Applications}.
\newblock Springer Berlin Heidelberg, 2010.
 \begin{quotation}\noindent This chapter presents a discussion of various
  techniques for integrating \ac{eeg} and \ac{fmri} information. The goal is to
  formulate an accurate representation of brain activity with the spatial
  density of \ac{fmri} and temporal density of \ac{eeg}. Asymmetrical
  approaches use one form of data as a predictor for details of the other form,
  for example \ac{eeg} and its temporal density (resp. \ac{fmri} and its
  spatial density) as a predictor for temporal details of \ac{fmri} (resp.
  spatial details of \ac{eeg}). These models assume a strong level of truth to
  the predictor data. Symmetrical approaches, information fusion, equally
  weight the different types of data and attempt to identify complementary
  features. The goal of these techniques is to invert the data, taking \ac{eeg}
  (resp. \ac{fmri}) from [scalp-measured voltage] (resp. \ac{bold} signal) to
  underlying neural activity. \end{quotation}

\bibitem[MPC{\etalchar{+}}07]{Mantini2007598}
D.~Mantini, M.G. Perrucci, S.~Cugini, A.~Ferretti, G.L. Romani, and C.~Del
  Gratta.
\newblock Complete artifact removal for \{EEG\} recorded during continuous
  \ac{fmri} using independent component analysis.
\newblock {\em NeuroImage}, 34(2):598 -- 607, 2007.
 \begin{quotation}\noindent Simultaneous recording of \ac{eeg} and \ac{fmri}
  data is useful in combining the strengths of both procedures. However,
  \ac{eeg} recordings made in the \ac{mri} become contaminated by both
  physiological and environmental disturbances in the \ac{mri} environment.
  Mantini et al. propose a method of using \ac{ica} to remove
  ballistocardiographic (BCG) and ocular artifacts along with contamination due
  to \ac{mri} from the data. The source signals were separated into brain
  signals and artifacts through manual and automated classification, and
  artifacts were subtracted from the data. In doing so, desired signals were
  recovered and noise free data was reconstructed to be used for later clinical
  study. \end{quotation}

\bibitem[PLD05]{1453511}
H.~Peng, Fulmi Long, and C.~Ding.
\newblock Feature selection based on mutual information criteria of
  max-dependency, max-relevance, and min-redundancy.
\newblock {\em Pattern Analysis and Machine Intelligence, IEEE Transactions
  on}, 27(8):1226--1238, 2005.
 \begin{quotation}\noindent Peng et al. present a method for efficiently
  selecting the most important factors in a dataset after distinct classes
  (clusters) have been distingushed. They present the Max-Relevance,
  Min-Redundancy criteria (\emph{mRMR}), based on the principle of mutual
  information for bivariate joint probability density functions. This process
  is presented in contrasted to the Max-Dependency criteria, which requires
  joint probability functions of higher dimensions (these are characterized as
  ill-posed problems). \end{quotation}

\bibitem[PM02]{ISI:000180426300003}
RD~Pascual-Marqui.
\newblock {Standardized low-resolution brain electromagnetic tomography
  (sLORETA): Technical details}.
\newblock {\em {METHODS AND FINDINGS IN EXPERIMENTAL AND CLINICAL
  PHARMACOLOGY}}, {24}({D}):{5--12}, {2002}.
\newblock {12th Meeting of the International-Pharmaco-EEG-Group, BARCELONA,
  SPAIN, NOV 21-24, 2002}.
 \begin{quotation}\noindent [Not 100\% citation]sLORETA is a technique for
  transforming the \ac{eeg} recordings from spatially diffuse electrode space
  into MR voxel space. It is currently the best solution to the inverse problem
  for finding the exact sources of neural activity as it is instantaneous,
  distributed, discreate and linear. It is also accurate for localizing
  electrode readings whose sources are deep in the cortex. Importantly, sLORETA
  computes with a zero localization error. \end{quotation}

\bibitem[Shl03]{pcatut}
John Shlens.
\newblock A tutorial on principal component analysis derivation, discussion and
  singular value decomposition.
\newblock Technical report, University of California San Diego, March 2003.
 \begin{quotation}\noindent Principal component analysis provides a method for
  reducing the dimensionality of data--or more importantly, reducing redundancy
  and noise. It is derived from the assumption that noise and redundant data
  will typically exhibit low variance, whereas the principal components will
  exhibit higher variance. It is proven that given a few additional
  assumptions, the principal components can be obtained from the original data
  by applying a linear transformation to the original data. This linear
  transform is obtained from the assumption that we wish to diagonalize the
  covariance matrix--and therefore reduce the redundancy of the data.
  \end{quotation}
\bibitem[vL07]{DBLP:journals/corr/abs-0711-0189}
Ulrike von Luxburg.
\newblock A tutorial on spectral clustering.
\newblock {\em CoRR}, abs/0711.0189, 2007.
 \begin{quotation}\noindent Spectral clustering first involves the
  establishment of a graph and definition of a pairwise vertex similarity
  metric. A graph type ($\epsilon$-neighborhood, $k$-nearest and mutual
  $k$-nearest neighborhood, fully-connected) must be specified. The type of
  Laplacian (normalized random-walk, normalized symmetric, or unnormalized)
  should be chosen, and the Laplacian matrix computed. A matrix should be
  created with columns consisting of the $k$ smallest eigenvectors of the
  Laplacian matrix. The row vectors of this new matrix should be partitioned
  into $k$ classes, via $k$-means clustering. If the $i$th row vector was
  assigned to the $j$th cluster, then the $i$th vertex in the training set is
  assigned to some $j$th cluster of vertices. Temporal lobe epilepsy is
  characterized by newly-presented hypometabolic features in some region of the
  brain. Spectral clustering could be applied to the diagnostic problem by
  identifying the patient as having a specific class of epilepsy (bilateral,
  \ac{ltle}, \ac{rtle}, unlateralized) based on which ROI has experienced the
  hypometabolism. Toward the \ac{fmri}/\ac{eeg} fusion problem: after
  transforming \ac{eeg} spectral bands onto \ac{fmri} voxel space, different
  spectral bands (either single or multiple bands at a time) could be clustered
  with \ac{fmri} signal. In this scheme the spectral band data and \ac{fmri}
  data would be vertices on a graph that is weighted based on temporal
  proximity, similarity in signal strength, or another factor. \end{quotation}

\end{thebibliography}
